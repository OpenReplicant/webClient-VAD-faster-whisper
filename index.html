<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>VAD->Faster-Whisper Component Set</title>
</head>

<body>

  <h2>Voice Activity Detection + Faster-Whisper</h2>
  <h2>= Always-on instant transcription service</h2>
  <h3>See console.log for outputs.</h3>

  <p>Sends POST request to <span>/transcribe</span> with audio data in .wav format.</p>
  <p>Returns JSON:</p>
  <pre>
{
  "transcribed_segments": [
      {"text": "<transcribed text>", "start": <start_time>, "end": <end_time>}
  ],
  "language": "<lang code>"
}
  </pre>


  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js"></script>
  <script>
    // Custom function to encode WAV from the Float32Array output by the VAD library.
    // There are libraries that accomplish this, but here's the code, generated by ChatGPT...
    function float32ToWav(floatArray, sampleRate) {
      const buffer = new ArrayBuffer(44 + floatArray.length * 2);
      const view = new DataView(buffer);

      // Set up the RIFF chunk descriptor
      writeString(view, 0, "RIFF");
      view.setUint32(4, 36 + floatArray.length * 2, true);
      writeString(view, 8, "WAVE");

      // Set up the fmt sub-chunk
      writeString(view, 12, "fmt ");
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, 1, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);

      // Set up the data sub-chunk
      writeString(view, 36, "data");
      view.setUint32(40, floatArray.length * 2, true);

      // Convert floatArray to Int16Array
      const intArray = new Int16Array(floatArray.length);
      for (let i = 0; i < floatArray.length; i++) {
        const floatValue = Math.max(-1, Math.min(1, floatArray[i]));
        intArray[i] = floatValue < 0 ? floatValue * 0x8000 : floatValue * 0x7FFF;
      }

      // Write audio data
      const dataView = new DataView(buffer, 44);
      for (let i = 0; i < intArray.length; i++) {
        dataView.setInt16(i * 2, intArray[i], true);
      }

      return buffer;
    }

    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }


    // Voice Activity Detection (VAD) loop
    async function main() {
      const myvad = await vad.MicVAD.new({
        onSpeechStart: () => {
          console.log("Speech start detected")
        },
        onSpeechEnd: async (audio) => {
          let wav = float32ToWav(audio, 16000)
          let blobber = new Blob([wav], { type: 'audio/wav' });
          console.log(blobber)

          //DEBUG
          //const downloadLink = document.createElement('a');
          //downloadLink.href = URL.createObjectURL(blobber);
          //downloadLink.download = 'transcription.wav';
          //downloadLink.click();

          
          // POST to Faster-Whisper endpoint
          fetch('http://localhost:3157/transcribe', {
            method: 'POST',
            headers: {
              'Content-Type': 'audio/wav'
            },
            body: blobber
          })
            .then(response => response.transcribed_segments())
            .then(transcribed_segments => {

              // OUTPUT HANDLER
              // Anything you want to do on the web client with STT.

              console.log('STT:', transcribed_segments);
            })
            .catch(error => {
              console.error('Transcription failed:', error);
            });
        }

      })
    myvad.start()
  }
  main()
  </script>
  
</body>
</html>
